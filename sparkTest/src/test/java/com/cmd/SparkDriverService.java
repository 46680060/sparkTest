/**
 * Autogenerated by Thrift Compiler (0.9.2)
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 *  @generated
 */
package com.cmd;

import org.apache.thrift.scheme.IScheme;
import org.apache.thrift.scheme.SchemeFactory;
import org.apache.thrift.scheme.StandardScheme;

import org.apache.thrift.scheme.TupleScheme;
import org.apache.thrift.protocol.TTupleProtocol;
import org.apache.thrift.protocol.TProtocolException;
import org.apache.thrift.EncodingUtils;
import org.apache.thrift.TException;
import org.apache.thrift.async.AsyncMethodCallback;
import org.apache.thrift.server.AbstractNonblockingServer.*;
import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.nio.ByteBuffer;
import java.util.Arrays;
import javax.annotation.Generated;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

@SuppressWarnings({"cast", "rawtypes", "serial", "unchecked"})
@Generated(value = "Autogenerated by Thrift Compiler (0.9.2)", date = "2016-9-13")
public class SparkDriverService {

  /**
   * 通往计算平台的RPC服务
   * 
   * 
   */
  public interface Iface {

    public String commitAccountJobToSpark(int accountId) throws org.apache.thrift.TException;

    public String commitBalanceJobToSpark(int balanceId) throws org.apache.thrift.TException;

    public String commitJobToSpark(String sparkString) throws org.apache.thrift.TException;

  }

  public interface AsyncIface {

    public void commitAccountJobToSpark(int accountId, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException;

    public void commitBalanceJobToSpark(int balanceId, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException;

    public void commitJobToSpark(String sparkString, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException;

  }

  public static class Client extends org.apache.thrift.TServiceClient implements Iface {
    public static class Factory implements org.apache.thrift.TServiceClientFactory<Client> {
      public Factory() {}
      public Client getClient(org.apache.thrift.protocol.TProtocol prot) {
        return new Client(prot);
      }
      public Client getClient(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
        return new Client(iprot, oprot);
      }
    }

    public Client(org.apache.thrift.protocol.TProtocol prot)
    {
      super(prot, prot);
    }

    public Client(org.apache.thrift.protocol.TProtocol iprot, org.apache.thrift.protocol.TProtocol oprot) {
      super(iprot, oprot);
    }

    public String commitAccountJobToSpark(int accountId) throws org.apache.thrift.TException
    {
      send_commitAccountJobToSpark(accountId);
      return recv_commitAccountJobToSpark();
    }

    public void send_commitAccountJobToSpark(int accountId) throws org.apache.thrift.TException
    {
      commitAccountJobToSpark_args args = new commitAccountJobToSpark_args();
      args.setAccountId(accountId);
      sendBase("commitAccountJobToSpark", args);
    }

    public String recv_commitAccountJobToSpark() throws org.apache.thrift.TException
    {
      commitAccountJobToSpark_result result = new commitAccountJobToSpark_result();
      receiveBase(result, "commitAccountJobToSpark");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "commitAccountJobToSpark failed: unknown result");
    }

    public String commitBalanceJobToSpark(int balanceId) throws org.apache.thrift.TException
    {
      send_commitBalanceJobToSpark(balanceId);
      return recv_commitBalanceJobToSpark();
    }

    public void send_commitBalanceJobToSpark(int balanceId) throws org.apache.thrift.TException
    {
      commitBalanceJobToSpark_args args = new commitBalanceJobToSpark_args();
      args.setBalanceId(balanceId);
      sendBase("commitBalanceJobToSpark", args);
    }

    public String recv_commitBalanceJobToSpark() throws org.apache.thrift.TException
    {
      commitBalanceJobToSpark_result result = new commitBalanceJobToSpark_result();
      receiveBase(result, "commitBalanceJobToSpark");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "commitBalanceJobToSpark failed: unknown result");
    }

    public String commitJobToSpark(String sparkString) throws org.apache.thrift.TException
    {
      send_commitJobToSpark(sparkString);
      return recv_commitJobToSpark();
    }

    public void send_commitJobToSpark(String sparkString) throws org.apache.thrift.TException
    {
      commitJobToSpark_args args = new commitJobToSpark_args();
      args.setSparkString(sparkString);
      sendBase("commitJobToSpark", args);
    }

    public String recv_commitJobToSpark() throws org.apache.thrift.TException
    {
      commitJobToSpark_result result = new commitJobToSpark_result();
      receiveBase(result, "commitJobToSpark");
      if (result.isSetSuccess()) {
        return result.success;
      }
      throw new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.MISSING_RESULT, "commitJobToSpark failed: unknown result");
    }

  }
  public static class AsyncClient extends org.apache.thrift.async.TAsyncClient implements AsyncIface {
    public static class Factory implements org.apache.thrift.async.TAsyncClientFactory<AsyncClient> {
      private org.apache.thrift.async.TAsyncClientManager clientManager;
      private org.apache.thrift.protocol.TProtocolFactory protocolFactory;
      public Factory(org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.protocol.TProtocolFactory protocolFactory) {
        this.clientManager = clientManager;
        this.protocolFactory = protocolFactory;
      }
      public AsyncClient getAsyncClient(org.apache.thrift.transport.TNonblockingTransport transport) {
        return new AsyncClient(protocolFactory, clientManager, transport);
      }
    }

    public AsyncClient(org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.async.TAsyncClientManager clientManager, org.apache.thrift.transport.TNonblockingTransport transport) {
      super(protocolFactory, clientManager, transport);
    }

    public void commitAccountJobToSpark(int accountId, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {
      checkReady();
      commitAccountJobToSpark_call method_call = new commitAccountJobToSpark_call(accountId, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class commitAccountJobToSpark_call extends org.apache.thrift.async.TAsyncMethodCall {
      private int accountId;
      public commitAccountJobToSpark_call(int accountId, org.apache.thrift.async.AsyncMethodCallback resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.accountId = accountId;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("commitAccountJobToSpark", org.apache.thrift.protocol.TMessageType.CALL, 0));
        commitAccountJobToSpark_args args = new commitAccountJobToSpark_args();
        args.setAccountId(accountId);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public String getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_commitAccountJobToSpark();
      }
    }

    public void commitBalanceJobToSpark(int balanceId, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {
      checkReady();
      commitBalanceJobToSpark_call method_call = new commitBalanceJobToSpark_call(balanceId, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class commitBalanceJobToSpark_call extends org.apache.thrift.async.TAsyncMethodCall {
      private int balanceId;
      public commitBalanceJobToSpark_call(int balanceId, org.apache.thrift.async.AsyncMethodCallback resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.balanceId = balanceId;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("commitBalanceJobToSpark", org.apache.thrift.protocol.TMessageType.CALL, 0));
        commitBalanceJobToSpark_args args = new commitBalanceJobToSpark_args();
        args.setBalanceId(balanceId);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public String getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_commitBalanceJobToSpark();
      }
    }

    public void commitJobToSpark(String sparkString, org.apache.thrift.async.AsyncMethodCallback resultHandler) throws org.apache.thrift.TException {
      checkReady();
      commitJobToSpark_call method_call = new commitJobToSpark_call(sparkString, resultHandler, this, ___protocolFactory, ___transport);
      this.___currentMethod = method_call;
      ___manager.call(method_call);
    }

    public static class commitJobToSpark_call extends org.apache.thrift.async.TAsyncMethodCall {
      private String sparkString;
      public commitJobToSpark_call(String sparkString, org.apache.thrift.async.AsyncMethodCallback resultHandler, org.apache.thrift.async.TAsyncClient client, org.apache.thrift.protocol.TProtocolFactory protocolFactory, org.apache.thrift.transport.TNonblockingTransport transport) throws org.apache.thrift.TException {
        super(client, protocolFactory, transport, resultHandler, false);
        this.sparkString = sparkString;
      }

      public void write_args(org.apache.thrift.protocol.TProtocol prot) throws org.apache.thrift.TException {
        prot.writeMessageBegin(new org.apache.thrift.protocol.TMessage("commitJobToSpark", org.apache.thrift.protocol.TMessageType.CALL, 0));
        commitJobToSpark_args args = new commitJobToSpark_args();
        args.setSparkString(sparkString);
        args.write(prot);
        prot.writeMessageEnd();
      }

      public String getResult() throws org.apache.thrift.TException {
        if (getState() != org.apache.thrift.async.TAsyncMethodCall.State.RESPONSE_READ) {
          throw new IllegalStateException("Method call not finished!");
        }
        org.apache.thrift.transport.TMemoryInputTransport memoryTransport = new org.apache.thrift.transport.TMemoryInputTransport(getFrameBuffer().array());
        org.apache.thrift.protocol.TProtocol prot = client.getProtocolFactory().getProtocol(memoryTransport);
        return (new Client(prot)).recv_commitJobToSpark();
      }
    }

  }

  public static class Processor<I extends Iface> extends org.apache.thrift.TBaseProcessor<I> implements org.apache.thrift.TProcessor {
    private static final Logger LOGGER = LoggerFactory.getLogger(Processor.class.getName());
    public Processor(I iface) {
      super(iface, getProcessMap(new HashMap<String, org.apache.thrift.ProcessFunction<I, ? extends org.apache.thrift.TBase>>()));
    }

    protected Processor(I iface, Map<String,  org.apache.thrift.ProcessFunction<I, ? extends  org.apache.thrift.TBase>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends Iface> Map<String,  org.apache.thrift.ProcessFunction<I, ? extends  org.apache.thrift.TBase>> getProcessMap(Map<String,  org.apache.thrift.ProcessFunction<I, ? extends  org.apache.thrift.TBase>> processMap) {
      processMap.put("commitAccountJobToSpark", new commitAccountJobToSpark());
      processMap.put("commitBalanceJobToSpark", new commitBalanceJobToSpark());
      processMap.put("commitJobToSpark", new commitJobToSpark());
      return processMap;
    }

    public static class commitAccountJobToSpark<I extends Iface> extends org.apache.thrift.ProcessFunction<I, commitAccountJobToSpark_args> {
      public commitAccountJobToSpark() {
        super("commitAccountJobToSpark");
      }

      public commitAccountJobToSpark_args getEmptyArgsInstance() {
        return new commitAccountJobToSpark_args();
      }

      protected boolean isOneway() {
        return false;
      }

      public commitAccountJobToSpark_result getResult(I iface, commitAccountJobToSpark_args args) throws org.apache.thrift.TException {
        commitAccountJobToSpark_result result = new commitAccountJobToSpark_result();
        result.success = iface.commitAccountJobToSpark(args.accountId);
        return result;
      }
    }

    public static class commitBalanceJobToSpark<I extends Iface> extends org.apache.thrift.ProcessFunction<I, commitBalanceJobToSpark_args> {
      public commitBalanceJobToSpark() {
        super("commitBalanceJobToSpark");
      }

      public commitBalanceJobToSpark_args getEmptyArgsInstance() {
        return new commitBalanceJobToSpark_args();
      }

      protected boolean isOneway() {
        return false;
      }

      public commitBalanceJobToSpark_result getResult(I iface, commitBalanceJobToSpark_args args) throws org.apache.thrift.TException {
        commitBalanceJobToSpark_result result = new commitBalanceJobToSpark_result();
        result.success = iface.commitBalanceJobToSpark(args.balanceId);
        return result;
      }
    }

    public static class commitJobToSpark<I extends Iface> extends org.apache.thrift.ProcessFunction<I, commitJobToSpark_args> {
      public commitJobToSpark() {
        super("commitJobToSpark");
      }

      public commitJobToSpark_args getEmptyArgsInstance() {
        return new commitJobToSpark_args();
      }

      protected boolean isOneway() {
        return false;
      }

      public commitJobToSpark_result getResult(I iface, commitJobToSpark_args args) throws org.apache.thrift.TException {
        commitJobToSpark_result result = new commitJobToSpark_result();
        result.success = iface.commitJobToSpark(args.sparkString);
        return result;
      }
    }

  }

  public static class AsyncProcessor<I extends AsyncIface> extends org.apache.thrift.TBaseAsyncProcessor<I> {
    private static final Logger LOGGER = LoggerFactory.getLogger(AsyncProcessor.class.getName());
    public AsyncProcessor(I iface) {
      super(iface, getProcessMap(new HashMap<String, org.apache.thrift.AsyncProcessFunction<I, ? extends org.apache.thrift.TBase, ?>>()));
    }

    protected AsyncProcessor(I iface, Map<String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      super(iface, getProcessMap(processMap));
    }

    private static <I extends AsyncIface> Map<String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase,?>> getProcessMap(Map<String,  org.apache.thrift.AsyncProcessFunction<I, ? extends  org.apache.thrift.TBase, ?>> processMap) {
      processMap.put("commitAccountJobToSpark", new commitAccountJobToSpark());
      processMap.put("commitBalanceJobToSpark", new commitBalanceJobToSpark());
      processMap.put("commitJobToSpark", new commitJobToSpark());
      return processMap;
    }

    public static class commitAccountJobToSpark<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, commitAccountJobToSpark_args, String> {
      public commitAccountJobToSpark() {
        super("commitAccountJobToSpark");
      }

      public commitAccountJobToSpark_args getEmptyArgsInstance() {
        return new commitAccountJobToSpark_args();
      }

      public AsyncMethodCallback<String> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new AsyncMethodCallback<String>() { 
          public void onComplete(String o) {
            commitAccountJobToSpark_result result = new commitAccountJobToSpark_result();
            result.success = o;
            try {
              fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
              return;
            } catch (Exception e) {
              LOGGER.error("Exception writing to internal frame buffer", e);
            }
            fb.close();
          }
          public void onError(Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TBase msg;
            commitAccountJobToSpark_result result = new commitAccountJobToSpark_result();
            {
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
              return;
            } catch (Exception ex) {
              LOGGER.error("Exception writing to internal frame buffer", ex);
            }
            fb.close();
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, commitAccountJobToSpark_args args, org.apache.thrift.async.AsyncMethodCallback<String> resultHandler) throws TException {
        iface.commitAccountJobToSpark(args.accountId,resultHandler);
      }
    }

    public static class commitBalanceJobToSpark<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, commitBalanceJobToSpark_args, String> {
      public commitBalanceJobToSpark() {
        super("commitBalanceJobToSpark");
      }

      public commitBalanceJobToSpark_args getEmptyArgsInstance() {
        return new commitBalanceJobToSpark_args();
      }

      public AsyncMethodCallback<String> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new AsyncMethodCallback<String>() { 
          public void onComplete(String o) {
            commitBalanceJobToSpark_result result = new commitBalanceJobToSpark_result();
            result.success = o;
            try {
              fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
              return;
            } catch (Exception e) {
              LOGGER.error("Exception writing to internal frame buffer", e);
            }
            fb.close();
          }
          public void onError(Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TBase msg;
            commitBalanceJobToSpark_result result = new commitBalanceJobToSpark_result();
            {
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
              return;
            } catch (Exception ex) {
              LOGGER.error("Exception writing to internal frame buffer", ex);
            }
            fb.close();
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, commitBalanceJobToSpark_args args, org.apache.thrift.async.AsyncMethodCallback<String> resultHandler) throws TException {
        iface.commitBalanceJobToSpark(args.balanceId,resultHandler);
      }
    }

    public static class commitJobToSpark<I extends AsyncIface> extends org.apache.thrift.AsyncProcessFunction<I, commitJobToSpark_args, String> {
      public commitJobToSpark() {
        super("commitJobToSpark");
      }

      public commitJobToSpark_args getEmptyArgsInstance() {
        return new commitJobToSpark_args();
      }

      public AsyncMethodCallback<String> getResultHandler(final AsyncFrameBuffer fb, final int seqid) {
        final org.apache.thrift.AsyncProcessFunction fcall = this;
        return new AsyncMethodCallback<String>() { 
          public void onComplete(String o) {
            commitJobToSpark_result result = new commitJobToSpark_result();
            result.success = o;
            try {
              fcall.sendResponse(fb,result, org.apache.thrift.protocol.TMessageType.REPLY,seqid);
              return;
            } catch (Exception e) {
              LOGGER.error("Exception writing to internal frame buffer", e);
            }
            fb.close();
          }
          public void onError(Exception e) {
            byte msgType = org.apache.thrift.protocol.TMessageType.REPLY;
            org.apache.thrift.TBase msg;
            commitJobToSpark_result result = new commitJobToSpark_result();
            {
              msgType = org.apache.thrift.protocol.TMessageType.EXCEPTION;
              msg = (org.apache.thrift.TBase)new org.apache.thrift.TApplicationException(org.apache.thrift.TApplicationException.INTERNAL_ERROR, e.getMessage());
            }
            try {
              fcall.sendResponse(fb,msg,msgType,seqid);
              return;
            } catch (Exception ex) {
              LOGGER.error("Exception writing to internal frame buffer", ex);
            }
            fb.close();
          }
        };
      }

      protected boolean isOneway() {
        return false;
      }

      public void start(I iface, commitJobToSpark_args args, org.apache.thrift.async.AsyncMethodCallback<String> resultHandler) throws TException {
        iface.commitJobToSpark(args.sparkString,resultHandler);
      }
    }

  }

  public static class commitAccountJobToSpark_args implements org.apache.thrift.TBase<commitAccountJobToSpark_args, commitAccountJobToSpark_args._Fields>, java.io.Serializable, Cloneable, Comparable<commitAccountJobToSpark_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitAccountJobToSpark_args");

    private static final org.apache.thrift.protocol.TField ACCOUNT_ID_FIELD_DESC = new org.apache.thrift.protocol.TField("accountId", org.apache.thrift.protocol.TType.I32, (short)1);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitAccountJobToSpark_argsStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitAccountJobToSpark_argsTupleSchemeFactory());
    }

    public int accountId; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      ACCOUNT_ID((short)1, "accountId");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // ACCOUNT_ID
            return ACCOUNT_ID;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __ACCOUNTID_ISSET_ID = 0;
    private byte __isset_bitfield = 0;
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.ACCOUNT_ID, new org.apache.thrift.meta_data.FieldMetaData("accountId", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitAccountJobToSpark_args.class, metaDataMap);
    }

    public commitAccountJobToSpark_args() {
    }

    public commitAccountJobToSpark_args(
      int accountId)
    {
      this();
      this.accountId = accountId;
      setAccountIdIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitAccountJobToSpark_args(commitAccountJobToSpark_args other) {
      __isset_bitfield = other.__isset_bitfield;
      this.accountId = other.accountId;
    }

    public commitAccountJobToSpark_args deepCopy() {
      return new commitAccountJobToSpark_args(this);
    }

    @Override
    public void clear() {
      setAccountIdIsSet(false);
      this.accountId = 0;
    }

    public int getAccountId() {
      return this.accountId;
    }

    public commitAccountJobToSpark_args setAccountId(int accountId) {
      this.accountId = accountId;
      setAccountIdIsSet(true);
      return this;
    }

    public void unsetAccountId() {
      __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __ACCOUNTID_ISSET_ID);
    }

    /** Returns true if field accountId is set (has been assigned a value) and false otherwise */
    public boolean isSetAccountId() {
      return EncodingUtils.testBit(__isset_bitfield, __ACCOUNTID_ISSET_ID);
    }

    public void setAccountIdIsSet(boolean value) {
      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __ACCOUNTID_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ACCOUNT_ID:
        if (value == null) {
          unsetAccountId();
        } else {
          setAccountId((Integer)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ACCOUNT_ID:
        return Integer.valueOf(getAccountId());

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case ACCOUNT_ID:
        return isSetAccountId();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitAccountJobToSpark_args)
        return this.equals((commitAccountJobToSpark_args)that);
      return false;
    }

    public boolean equals(commitAccountJobToSpark_args that) {
      if (that == null)
        return false;

      boolean this_present_accountId = true;
      boolean that_present_accountId = true;
      if (this_present_accountId || that_present_accountId) {
        if (!(this_present_accountId && that_present_accountId))
          return false;
        if (this.accountId != that.accountId)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_accountId = true;
      list.add(present_accountId);
      if (present_accountId)
        list.add(accountId);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitAccountJobToSpark_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetAccountId()).compareTo(other.isSetAccountId());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetAccountId()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.accountId, other.accountId);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitAccountJobToSpark_args(");
      boolean first = true;

      sb.append("accountId:");
      sb.append(this.accountId);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
        __isset_bitfield = 0;
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitAccountJobToSpark_argsStandardSchemeFactory implements SchemeFactory {
      public commitAccountJobToSpark_argsStandardScheme getScheme() {
        return new commitAccountJobToSpark_argsStandardScheme();
      }
    }

    private static class commitAccountJobToSpark_argsStandardScheme extends StandardScheme<commitAccountJobToSpark_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitAccountJobToSpark_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // ACCOUNT_ID
              if (schemeField.type == org.apache.thrift.protocol.TType.I32) {
                struct.accountId = iprot.readI32();
                struct.setAccountIdIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitAccountJobToSpark_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        oprot.writeFieldBegin(ACCOUNT_ID_FIELD_DESC);
        oprot.writeI32(struct.accountId);
        oprot.writeFieldEnd();
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitAccountJobToSpark_argsTupleSchemeFactory implements SchemeFactory {
      public commitAccountJobToSpark_argsTupleScheme getScheme() {
        return new commitAccountJobToSpark_argsTupleScheme();
      }
    }

    private static class commitAccountJobToSpark_argsTupleScheme extends TupleScheme<commitAccountJobToSpark_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitAccountJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetAccountId()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetAccountId()) {
          oprot.writeI32(struct.accountId);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitAccountJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.accountId = iprot.readI32();
          struct.setAccountIdIsSet(true);
        }
      }
    }

  }

  public static class commitAccountJobToSpark_result implements org.apache.thrift.TBase<commitAccountJobToSpark_result, commitAccountJobToSpark_result._Fields>, java.io.Serializable, Cloneable, Comparable<commitAccountJobToSpark_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitAccountJobToSpark_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRING, (short)0);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitAccountJobToSpark_resultStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitAccountJobToSpark_resultTupleSchemeFactory());
    }

    public String success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitAccountJobToSpark_result.class, metaDataMap);
    }

    public commitAccountJobToSpark_result() {
    }

    public commitAccountJobToSpark_result(
      String success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitAccountJobToSpark_result(commitAccountJobToSpark_result other) {
      if (other.isSetSuccess()) {
        this.success = other.success;
      }
    }

    public commitAccountJobToSpark_result deepCopy() {
      return new commitAccountJobToSpark_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public String getSuccess() {
      return this.success;
    }

    public commitAccountJobToSpark_result setSuccess(String success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((String)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitAccountJobToSpark_result)
        return this.equals((commitAccountJobToSpark_result)that);
      return false;
    }

    public boolean equals(commitAccountJobToSpark_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_success = true && (isSetSuccess());
      list.add(present_success);
      if (present_success)
        list.add(success);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitAccountJobToSpark_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
      }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitAccountJobToSpark_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitAccountJobToSpark_resultStandardSchemeFactory implements SchemeFactory {
      public commitAccountJobToSpark_resultStandardScheme getScheme() {
        return new commitAccountJobToSpark_resultStandardScheme();
      }
    }

    private static class commitAccountJobToSpark_resultStandardScheme extends StandardScheme<commitAccountJobToSpark_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitAccountJobToSpark_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.success = iprot.readString();
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitAccountJobToSpark_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          oprot.writeString(struct.success);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitAccountJobToSpark_resultTupleSchemeFactory implements SchemeFactory {
      public commitAccountJobToSpark_resultTupleScheme getScheme() {
        return new commitAccountJobToSpark_resultTupleScheme();
      }
    }

    private static class commitAccountJobToSpark_resultTupleScheme extends TupleScheme<commitAccountJobToSpark_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitAccountJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          oprot.writeString(struct.success);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitAccountJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = iprot.readString();
          struct.setSuccessIsSet(true);
        }
      }
    }

  }

  public static class commitBalanceJobToSpark_args implements org.apache.thrift.TBase<commitBalanceJobToSpark_args, commitBalanceJobToSpark_args._Fields>, java.io.Serializable, Cloneable, Comparable<commitBalanceJobToSpark_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitBalanceJobToSpark_args");

    private static final org.apache.thrift.protocol.TField BALANCE_ID_FIELD_DESC = new org.apache.thrift.protocol.TField("balanceId", org.apache.thrift.protocol.TType.I32, (short)1);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitBalanceJobToSpark_argsStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitBalanceJobToSpark_argsTupleSchemeFactory());
    }

    public int balanceId; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      BALANCE_ID((short)1, "balanceId");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // BALANCE_ID
            return BALANCE_ID;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __BALANCEID_ISSET_ID = 0;
    private byte __isset_bitfield = 0;
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.BALANCE_ID, new org.apache.thrift.meta_data.FieldMetaData("balanceId", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.I32)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitBalanceJobToSpark_args.class, metaDataMap);
    }

    public commitBalanceJobToSpark_args() {
    }

    public commitBalanceJobToSpark_args(
      int balanceId)
    {
      this();
      this.balanceId = balanceId;
      setBalanceIdIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitBalanceJobToSpark_args(commitBalanceJobToSpark_args other) {
      __isset_bitfield = other.__isset_bitfield;
      this.balanceId = other.balanceId;
    }

    public commitBalanceJobToSpark_args deepCopy() {
      return new commitBalanceJobToSpark_args(this);
    }

    @Override
    public void clear() {
      setBalanceIdIsSet(false);
      this.balanceId = 0;
    }

    public int getBalanceId() {
      return this.balanceId;
    }

    public commitBalanceJobToSpark_args setBalanceId(int balanceId) {
      this.balanceId = balanceId;
      setBalanceIdIsSet(true);
      return this;
    }

    public void unsetBalanceId() {
      __isset_bitfield = EncodingUtils.clearBit(__isset_bitfield, __BALANCEID_ISSET_ID);
    }

    /** Returns true if field balanceId is set (has been assigned a value) and false otherwise */
    public boolean isSetBalanceId() {
      return EncodingUtils.testBit(__isset_bitfield, __BALANCEID_ISSET_ID);
    }

    public void setBalanceIdIsSet(boolean value) {
      __isset_bitfield = EncodingUtils.setBit(__isset_bitfield, __BALANCEID_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case BALANCE_ID:
        if (value == null) {
          unsetBalanceId();
        } else {
          setBalanceId((Integer)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case BALANCE_ID:
        return Integer.valueOf(getBalanceId());

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case BALANCE_ID:
        return isSetBalanceId();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitBalanceJobToSpark_args)
        return this.equals((commitBalanceJobToSpark_args)that);
      return false;
    }

    public boolean equals(commitBalanceJobToSpark_args that) {
      if (that == null)
        return false;

      boolean this_present_balanceId = true;
      boolean that_present_balanceId = true;
      if (this_present_balanceId || that_present_balanceId) {
        if (!(this_present_balanceId && that_present_balanceId))
          return false;
        if (this.balanceId != that.balanceId)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_balanceId = true;
      list.add(present_balanceId);
      if (present_balanceId)
        list.add(balanceId);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitBalanceJobToSpark_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetBalanceId()).compareTo(other.isSetBalanceId());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetBalanceId()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.balanceId, other.balanceId);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitBalanceJobToSpark_args(");
      boolean first = true;

      sb.append("balanceId:");
      sb.append(this.balanceId);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        // it doesn't seem like you should have to do this, but java serialization is wacky, and doesn't call the default constructor.
        __isset_bitfield = 0;
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitBalanceJobToSpark_argsStandardSchemeFactory implements SchemeFactory {
      public commitBalanceJobToSpark_argsStandardScheme getScheme() {
        return new commitBalanceJobToSpark_argsStandardScheme();
      }
    }

    private static class commitBalanceJobToSpark_argsStandardScheme extends StandardScheme<commitBalanceJobToSpark_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitBalanceJobToSpark_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // BALANCE_ID
              if (schemeField.type == org.apache.thrift.protocol.TType.I32) {
                struct.balanceId = iprot.readI32();
                struct.setBalanceIdIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitBalanceJobToSpark_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        oprot.writeFieldBegin(BALANCE_ID_FIELD_DESC);
        oprot.writeI32(struct.balanceId);
        oprot.writeFieldEnd();
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitBalanceJobToSpark_argsTupleSchemeFactory implements SchemeFactory {
      public commitBalanceJobToSpark_argsTupleScheme getScheme() {
        return new commitBalanceJobToSpark_argsTupleScheme();
      }
    }

    private static class commitBalanceJobToSpark_argsTupleScheme extends TupleScheme<commitBalanceJobToSpark_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitBalanceJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetBalanceId()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetBalanceId()) {
          oprot.writeI32(struct.balanceId);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitBalanceJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.balanceId = iprot.readI32();
          struct.setBalanceIdIsSet(true);
        }
      }
    }

  }

  public static class commitBalanceJobToSpark_result implements org.apache.thrift.TBase<commitBalanceJobToSpark_result, commitBalanceJobToSpark_result._Fields>, java.io.Serializable, Cloneable, Comparable<commitBalanceJobToSpark_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitBalanceJobToSpark_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRING, (short)0);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitBalanceJobToSpark_resultStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitBalanceJobToSpark_resultTupleSchemeFactory());
    }

    public String success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitBalanceJobToSpark_result.class, metaDataMap);
    }

    public commitBalanceJobToSpark_result() {
    }

    public commitBalanceJobToSpark_result(
      String success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitBalanceJobToSpark_result(commitBalanceJobToSpark_result other) {
      if (other.isSetSuccess()) {
        this.success = other.success;
      }
    }

    public commitBalanceJobToSpark_result deepCopy() {
      return new commitBalanceJobToSpark_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public String getSuccess() {
      return this.success;
    }

    public commitBalanceJobToSpark_result setSuccess(String success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((String)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitBalanceJobToSpark_result)
        return this.equals((commitBalanceJobToSpark_result)that);
      return false;
    }

    public boolean equals(commitBalanceJobToSpark_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_success = true && (isSetSuccess());
      list.add(present_success);
      if (present_success)
        list.add(success);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitBalanceJobToSpark_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
      }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitBalanceJobToSpark_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitBalanceJobToSpark_resultStandardSchemeFactory implements SchemeFactory {
      public commitBalanceJobToSpark_resultStandardScheme getScheme() {
        return new commitBalanceJobToSpark_resultStandardScheme();
      }
    }

    private static class commitBalanceJobToSpark_resultStandardScheme extends StandardScheme<commitBalanceJobToSpark_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitBalanceJobToSpark_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.success = iprot.readString();
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitBalanceJobToSpark_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          oprot.writeString(struct.success);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitBalanceJobToSpark_resultTupleSchemeFactory implements SchemeFactory {
      public commitBalanceJobToSpark_resultTupleScheme getScheme() {
        return new commitBalanceJobToSpark_resultTupleScheme();
      }
    }

    private static class commitBalanceJobToSpark_resultTupleScheme extends TupleScheme<commitBalanceJobToSpark_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitBalanceJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          oprot.writeString(struct.success);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitBalanceJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = iprot.readString();
          struct.setSuccessIsSet(true);
        }
      }
    }

  }

  public static class commitJobToSpark_args implements org.apache.thrift.TBase<commitJobToSpark_args, commitJobToSpark_args._Fields>, java.io.Serializable, Cloneable, Comparable<commitJobToSpark_args>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitJobToSpark_args");

    private static final org.apache.thrift.protocol.TField SPARK_STRING_FIELD_DESC = new org.apache.thrift.protocol.TField("sparkString", org.apache.thrift.protocol.TType.STRING, (short)1);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitJobToSpark_argsStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitJobToSpark_argsTupleSchemeFactory());
    }

    public String sparkString; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SPARK_STRING((short)1, "sparkString");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 1: // SPARK_STRING
            return SPARK_STRING;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SPARK_STRING, new org.apache.thrift.meta_data.FieldMetaData("sparkString", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitJobToSpark_args.class, metaDataMap);
    }

    public commitJobToSpark_args() {
    }

    public commitJobToSpark_args(
      String sparkString)
    {
      this();
      this.sparkString = sparkString;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitJobToSpark_args(commitJobToSpark_args other) {
      if (other.isSetSparkString()) {
        this.sparkString = other.sparkString;
      }
    }

    public commitJobToSpark_args deepCopy() {
      return new commitJobToSpark_args(this);
    }

    @Override
    public void clear() {
      this.sparkString = null;
    }

    public String getSparkString() {
      return this.sparkString;
    }

    public commitJobToSpark_args setSparkString(String sparkString) {
      this.sparkString = sparkString;
      return this;
    }

    public void unsetSparkString() {
      this.sparkString = null;
    }

    /** Returns true if field sparkString is set (has been assigned a value) and false otherwise */
    public boolean isSetSparkString() {
      return this.sparkString != null;
    }

    public void setSparkStringIsSet(boolean value) {
      if (!value) {
        this.sparkString = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SPARK_STRING:
        if (value == null) {
          unsetSparkString();
        } else {
          setSparkString((String)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SPARK_STRING:
        return getSparkString();

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case SPARK_STRING:
        return isSetSparkString();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitJobToSpark_args)
        return this.equals((commitJobToSpark_args)that);
      return false;
    }

    public boolean equals(commitJobToSpark_args that) {
      if (that == null)
        return false;

      boolean this_present_sparkString = true && this.isSetSparkString();
      boolean that_present_sparkString = true && that.isSetSparkString();
      if (this_present_sparkString || that_present_sparkString) {
        if (!(this_present_sparkString && that_present_sparkString))
          return false;
        if (!this.sparkString.equals(that.sparkString))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_sparkString = true && (isSetSparkString());
      list.add(present_sparkString);
      if (present_sparkString)
        list.add(sparkString);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitJobToSpark_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetSparkString()).compareTo(other.isSetSparkString());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSparkString()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.sparkString, other.sparkString);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitJobToSpark_args(");
      boolean first = true;

      sb.append("sparkString:");
      if (this.sparkString == null) {
        sb.append("null");
      } else {
        sb.append(this.sparkString);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitJobToSpark_argsStandardSchemeFactory implements SchemeFactory {
      public commitJobToSpark_argsStandardScheme getScheme() {
        return new commitJobToSpark_argsStandardScheme();
      }
    }

    private static class commitJobToSpark_argsStandardScheme extends StandardScheme<commitJobToSpark_args> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitJobToSpark_args struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 1: // SPARK_STRING
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.sparkString = iprot.readString();
                struct.setSparkStringIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitJobToSpark_args struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.sparkString != null) {
          oprot.writeFieldBegin(SPARK_STRING_FIELD_DESC);
          oprot.writeString(struct.sparkString);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitJobToSpark_argsTupleSchemeFactory implements SchemeFactory {
      public commitJobToSpark_argsTupleScheme getScheme() {
        return new commitJobToSpark_argsTupleScheme();
      }
    }

    private static class commitJobToSpark_argsTupleScheme extends TupleScheme<commitJobToSpark_args> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetSparkString()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSparkString()) {
          oprot.writeString(struct.sparkString);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitJobToSpark_args struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.sparkString = iprot.readString();
          struct.setSparkStringIsSet(true);
        }
      }
    }

  }

  public static class commitJobToSpark_result implements org.apache.thrift.TBase<commitJobToSpark_result, commitJobToSpark_result._Fields>, java.io.Serializable, Cloneable, Comparable<commitJobToSpark_result>   {
    private static final org.apache.thrift.protocol.TStruct STRUCT_DESC = new org.apache.thrift.protocol.TStruct("commitJobToSpark_result");

    private static final org.apache.thrift.protocol.TField SUCCESS_FIELD_DESC = new org.apache.thrift.protocol.TField("success", org.apache.thrift.protocol.TType.STRING, (short)0);

    private static final Map<Class<? extends IScheme>, SchemeFactory> schemes = new HashMap<Class<? extends IScheme>, SchemeFactory>();
    static {
      schemes.put(StandardScheme.class, new commitJobToSpark_resultStandardSchemeFactory());
      schemes.put(TupleScheme.class, new commitJobToSpark_resultTupleSchemeFactory());
    }

    public String success; // required

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements org.apache.thrift.TFieldIdEnum {
      SUCCESS((short)0, "success");

      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        switch(fieldId) {
          case 0: // SUCCESS
            return SUCCESS;
          default:
            return null;
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    public static final Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> metaDataMap;
    static {
      Map<_Fields, org.apache.thrift.meta_data.FieldMetaData> tmpMap = new EnumMap<_Fields, org.apache.thrift.meta_data.FieldMetaData>(_Fields.class);
      tmpMap.put(_Fields.SUCCESS, new org.apache.thrift.meta_data.FieldMetaData("success", org.apache.thrift.TFieldRequirementType.DEFAULT, 
          new org.apache.thrift.meta_data.FieldValueMetaData(org.apache.thrift.protocol.TType.STRING)));
      metaDataMap = Collections.unmodifiableMap(tmpMap);
      org.apache.thrift.meta_data.FieldMetaData.addStructMetaDataMap(commitJobToSpark_result.class, metaDataMap);
    }

    public commitJobToSpark_result() {
    }

    public commitJobToSpark_result(
      String success)
    {
      this();
      this.success = success;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public commitJobToSpark_result(commitJobToSpark_result other) {
      if (other.isSetSuccess()) {
        this.success = other.success;
      }
    }

    public commitJobToSpark_result deepCopy() {
      return new commitJobToSpark_result(this);
    }

    @Override
    public void clear() {
      this.success = null;
    }

    public String getSuccess() {
      return this.success;
    }

    public commitJobToSpark_result setSuccess(String success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been assigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((String)value);
        }
        break;

      }
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      }
      throw new IllegalStateException();
    }

    /** Returns true if field corresponding to fieldID is set (has been assigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      if (field == null) {
        throw new IllegalArgumentException();
      }

      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      }
      throw new IllegalStateException();
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof commitJobToSpark_result)
        return this.equals((commitJobToSpark_result)that);
      return false;
    }

    public boolean equals(commitJobToSpark_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      List<Object> list = new ArrayList<Object>();

      boolean present_success = true && (isSetSuccess());
      list.add(present_success);
      if (present_success)
        list.add(success);

      return list.hashCode();
    }

    @Override
    public int compareTo(commitJobToSpark_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(other.isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      if (isSetSuccess()) {
        lastComparison = org.apache.thrift.TBaseHelper.compareTo(this.success, other.success);
        if (lastComparison != 0) {
          return lastComparison;
        }
      }
      return 0;
    }

    public _Fields fieldForId(int fieldId) {
      return _Fields.findByThriftId(fieldId);
    }

    public void read(org.apache.thrift.protocol.TProtocol iprot) throws org.apache.thrift.TException {
      schemes.get(iprot.getScheme()).getScheme().read(iprot, this);
    }

    public void write(org.apache.thrift.protocol.TProtocol oprot) throws org.apache.thrift.TException {
      schemes.get(oprot.getScheme()).getScheme().write(oprot, this);
      }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("commitJobToSpark_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws org.apache.thrift.TException {
      // check for required fields
      // check for sub-struct validity
    }

    private void writeObject(java.io.ObjectOutputStream out) throws java.io.IOException {
      try {
        write(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(out)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private void readObject(java.io.ObjectInputStream in) throws java.io.IOException, ClassNotFoundException {
      try {
        read(new org.apache.thrift.protocol.TCompactProtocol(new org.apache.thrift.transport.TIOStreamTransport(in)));
      } catch (org.apache.thrift.TException te) {
        throw new java.io.IOException(te);
      }
    }

    private static class commitJobToSpark_resultStandardSchemeFactory implements SchemeFactory {
      public commitJobToSpark_resultStandardScheme getScheme() {
        return new commitJobToSpark_resultStandardScheme();
      }
    }

    private static class commitJobToSpark_resultStandardScheme extends StandardScheme<commitJobToSpark_result> {

      public void read(org.apache.thrift.protocol.TProtocol iprot, commitJobToSpark_result struct) throws org.apache.thrift.TException {
        org.apache.thrift.protocol.TField schemeField;
        iprot.readStructBegin();
        while (true)
        {
          schemeField = iprot.readFieldBegin();
          if (schemeField.type == org.apache.thrift.protocol.TType.STOP) { 
            break;
          }
          switch (schemeField.id) {
            case 0: // SUCCESS
              if (schemeField.type == org.apache.thrift.protocol.TType.STRING) {
                struct.success = iprot.readString();
                struct.setSuccessIsSet(true);
              } else { 
                org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
              }
              break;
            default:
              org.apache.thrift.protocol.TProtocolUtil.skip(iprot, schemeField.type);
          }
          iprot.readFieldEnd();
        }
        iprot.readStructEnd();

        // check for required fields of primitive type, which can't be checked in the validate method
        struct.validate();
      }

      public void write(org.apache.thrift.protocol.TProtocol oprot, commitJobToSpark_result struct) throws org.apache.thrift.TException {
        struct.validate();

        oprot.writeStructBegin(STRUCT_DESC);
        if (struct.success != null) {
          oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
          oprot.writeString(struct.success);
          oprot.writeFieldEnd();
        }
        oprot.writeFieldStop();
        oprot.writeStructEnd();
      }

    }

    private static class commitJobToSpark_resultTupleSchemeFactory implements SchemeFactory {
      public commitJobToSpark_resultTupleScheme getScheme() {
        return new commitJobToSpark_resultTupleScheme();
      }
    }

    private static class commitJobToSpark_resultTupleScheme extends TupleScheme<commitJobToSpark_result> {

      @Override
      public void write(org.apache.thrift.protocol.TProtocol prot, commitJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol oprot = (TTupleProtocol) prot;
        BitSet optionals = new BitSet();
        if (struct.isSetSuccess()) {
          optionals.set(0);
        }
        oprot.writeBitSet(optionals, 1);
        if (struct.isSetSuccess()) {
          oprot.writeString(struct.success);
        }
      }

      @Override
      public void read(org.apache.thrift.protocol.TProtocol prot, commitJobToSpark_result struct) throws org.apache.thrift.TException {
        TTupleProtocol iprot = (TTupleProtocol) prot;
        BitSet incoming = iprot.readBitSet(1);
        if (incoming.get(0)) {
          struct.success = iprot.readString();
          struct.setSuccessIsSet(true);
        }
      }
    }

  }

}
